{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_0: Predicting Titanic Survivors.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcYm1lptGv-Y"
      },
      "source": [
        "# APS360 Lab 0 - Python and Libraries\n",
        "\n",
        "### Summary:\n",
        "\n",
        "Welcome to the first lab of APS360! This lab is\n",
        "a warm up to get you used to the programming environment used\n",
        "in the course, and also to help you review and renew your knowledge\n",
        "of Python and relevant Python libraries.\n",
        "The labs must be done **individually** and even though this lab is not for marks, it is recommended that you get into the practise of working alone.\n",
        "\n",
        "By the end of this lab, you should be able to:\n",
        "\n",
        "1. Setup and use Google Colab.\n",
        "2. Write basic, object-oriented Python code.\n",
        "3. Be able to perform matrix operations using `NumPy`.\n",
        "4. Be able to plot using `matplotlib`.\n",
        "5. Be able to load, process, and visualize data.\n",
        "6. Be able to perform basic machine learning operations using `Scikit-learn`.\n",
        "\n",
        "You will need to use NumPy, matplotlib and SciPy. Documentations for their libraries are provided:\n",
        "\n",
        "* https://docs.scipy.org/doc/numpy/reference/\n",
        "* https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot\n",
        "* https://scikit-learn.org/stable/supervised_learning.html\n",
        "\n",
        "You can also reference Python API documentations freely.\n",
        "\n",
        "### What to submit:\n",
        "\n",
        "**Nothing!** For future labs you will be required to submit a PDF file containing all your code, outputs, and write-up pertaining to the lab. You can produce a PDF of your Google Colab file by going to `File > Print` and then save as PDF. The Colab instructions has more information.\n",
        "\n",
        "Include a link to your colab file in your submission.\n",
        "\n",
        "Please use Google Colab to complete this assignment. If you want to use Jupyter Notebook, please complete the assignment and upload your Jupyter Notebook file to Google Colab for submission. \n",
        "\n",
        "With Colab, you can export a PDF file using the menu option\n",
        "`File -> Print` and save as PDF file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8drridLM3lT"
      },
      "source": [
        "## Colab Link\n",
        "\n",
        "Please make sure to include a link to your colab file here\n",
        "\n",
        "Colab Link: N/A, for future labs you will be required to provide a link to your Colab file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DFtJpz6PQXX"
      },
      "source": [
        "# Part 0\n",
        "\n",
        "# Environmental Setup\n",
        "\n",
        "Please refer to Colab instructions https://colab.research.google.com/drive/1YKHHLSlG-B9Ez2-zf-YFxXTVgfC_Aqtt\n",
        "\n",
        "If you want to use Jupyter Notebook locally, please refer to https://www.cs.toronto.edu/~lczhang/aps360_20191/files/install.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drWkYMQBGv-Z"
      },
      "source": [
        "# Part 1\n",
        "\n",
        "# Problem: Predicting Titanic Survivors\n",
        "\n",
        "![alt text](http://upload.wikimedia.org/wikipedia/commons/6/6e/St%C3%B6wer_Titanic.jpg)\n",
        "\n",
        "## Problem Background\n",
        "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This tragedy shocked the international community and led to better safety regulations for ships.\n",
        "\n",
        "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
        "\n",
        "In 1997, the story of the Titanic was brought to the big screen and it allowed us to relive the story of two passengers, Jack and Rose, members of  different social classes, who fall in love on the ill-fated passenger liner.\n",
        "\n",
        "How many of you have seen the movie Titanic?   \n",
        "\n",
        "Most of you probably were not born when the movie came out, so in case you have not seen it yet, Iâ€™m not going to spoil it. In this lab we are going to work with a Titanic dataset to determine what sort of people were likely to survive the disaster. In particular we would like to predict if Jack and Rose would have survived. Afterwards, those of you who have not seen the movie can go and watch it to see if our predictions match the Hollywood story."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU4cjlHeGv-a"
      },
      "source": [
        "## Define the Problem\n",
        "Our objective is to predict whether or not Jack and Rose would have survived the Titanic tragedy, based on what we know about them from the movie Titanic directed by James Cameron. \n",
        "\n",
        "From the movie we can assume the following about Jack and Rose:\n",
        "\n",
        "* Jack: 3rd class, no siblings, male, 25 years old, no cabin, fare = 7, embarked from Southhampton  \n",
        "* Rose: 1st class, no siblings, has spouse, 22 years old, cabin, fare = 50,  embarked from Southhampton\n",
        "\n",
        "To achieve this objective we are provided with historical data obtained after the Titanic tragedy. The historical data is provided as a CSV file containing information on 891 passengers as summarized below:\n",
        "\n",
        "<pre>\n",
        "PASSENGER INFORMATION:\n",
        "survival        Survival\n",
        "                (0 = No; 1 = Yes)\n",
        "pclass          Passenger Class\n",
        "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
        "name            Name\n",
        "sex             Sex\n",
        "age             Age\n",
        "sibsp           Number of Siblings/Spouses Aboard\n",
        "parch           Number of Parents/Children Aboard\n",
        "ticket          Ticket Number\n",
        "fare            Passenger Fare\n",
        "cabin           Cabin\n",
        "embarked        Port of Embarkation\n",
        "                (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
        "</pre>\n",
        "\n",
        "### Open Data using Spreadsheet Software\n",
        "\n",
        "To solve this problem we will start off by investigating the data. We will also be looking at a couple modules namely, numpy, matplotlib and scipy to achieve our objective of predicting passenger survival outcome. To start off let's open the file `train.csv` which you can find on Quercus under Lab 0, or using the following link:\n",
        "\n",
        "https://drive.google.com/open?id=1aOqkEx5mXBJ5u63NgJ_abRgzVs9awQh9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiAq9J7QGv-b"
      },
      "source": [
        "## Define Test Cases\n",
        "\n",
        "To validate our predictions we will create test cases with male a female survivors and non-survivors.\n",
        "\n",
        "  \n",
        "#### Test Case 1:  Sample Male and Female Survivor\n",
        "  \n",
        "|Passenger|PassengerID|Pclass|Sex|Age|SibSp|Parch|Fare|Embarked_Val|\n",
        "|:--------|:----------|:-----|:--|:--|:----|:----|:---|:-----------|\n",
        "|Mrs. Laina Heikkinen|3|3|1|26|0|0|7.925|2|\n",
        "|Master. Michel Navratil|194|2|0|3|1|1|26|2|\n",
        "\n",
        "#### Test Case 2:  Sample Male and Female Non-Survivor\n",
        "\n",
        "|Passenger|PassengerID|Pclass|Sex|Age|SibSp|Parch|Fare|Embarked_Val|\n",
        "|:--------|:----------|:-----|:--|:--|:----|:----|:---|:-----------|\n",
        "|Miss. Augusta Planke|39|3|1|18|2|0|18|2|\n",
        "|Mr. Owen Harris Braund|1|3|0|22|1|0|7.25|2|\n",
        "\n",
        "Once we are confident with the accuracy on accurately predicting survival on our test cases, we can then confidently predict what would happen to Jack and Rose.\n",
        "\n",
        "#### Test Case 3:  Jack and Rose from the movie Titanic\n",
        "\n",
        "|Passenger|Pclass|Sex|Age|SibSp|Parch|Fare|Embarked|\n",
        "|:--------|:-----|:--|:--|:----|:----|:---|:-----------|\n",
        "|Jack|3|male|25|0|0|7|S|\n",
        "|Rose|1|female|22|1|0|50|S|\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_m6kVe-Gv-c"
      },
      "source": [
        "## Loading and Accessing Titanic Dataset\n",
        "\n",
        "First let's review comma separated value (CSV) files. CSV files are simple text-based files well-suited for organizing spreadsheet data similar. In the CSV format all values are separated by a comma or some unique character. Using the Python csv module we can load our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkCy4jhl2rS7"
      },
      "source": [
        "# load train.csv to Google Colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uU5xScLCGv-c"
      },
      "source": [
        "import csv\n",
        "with open('train.csv','r') as csvfile:\n",
        "    data_reader = csv.reader(csvfile)\n",
        "\n",
        "    data_orig = []\n",
        "    for row in data_reader:\n",
        "        data_orig.append(row)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVMGwfTQbERi"
      },
      "source": [
        "(Optional) If you run into issues loading the file. You can also try the following code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8D2dnQebS7u"
      },
      "source": [
        "# link to your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTw8Mvwgbte0"
      },
      "source": [
        "# you will need to load the train.csv file to a folder on your Google Drive\n",
        "\n",
        "file_dir = '/content/drive/My Drive/Colab Notebooks/________/' #csv file location\n",
        "\n",
        "import csv\n",
        "with open(file_dir + 'train.csv','r') as csvfile:\n",
        "    data_reader = csv.reader(csvfile)\n",
        "\n",
        "    data_orig = []\n",
        "    for row in data_reader:\n",
        "        data_orig.append(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7LTD7V0Gv-g"
      },
      "source": [
        "Next we're going to look through our dataset to make sure it was loaded correctly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkqNo4zdGv-h"
      },
      "source": [
        "# display the full dataset\n",
        "print(data_orig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YiXqUZGGv-m"
      },
      "source": [
        "# display the first row (column titles) \n",
        "print(data_orig[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYytJvOJGv-p",
        "scrolled": true
      },
      "source": [
        "# display first two samples\n",
        "print(data_orig[1:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKD3iLzmGv-s"
      },
      "source": [
        "# how would you display the last five samples?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm605PTK3qIp"
      },
      "source": [
        "# how would you display the first five odd samples?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU6z_0Iw30dy"
      },
      "source": [
        "# can you find the Master. Michel Navratil, Passenger ID 194?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewMz2_pQGv-v"
      },
      "source": [
        "### Numpy Module\n",
        "\n",
        "Numpy provides support for working with multi-dimensional data such as our CSV file. In particular, it has a number of methods for efficient computation of linear algebra equations, provides capability for finding, extracting and/or changing information in multi-dimensional data, and allows for slicing of matrices simulataneously by column and row indices (i.e. using numpy in Python gives functionality similar to MATLAB).\n",
        "\n",
        "We'll highlight some of these traits as we proceed with our data analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtV9y3VcGv-w"
      },
      "source": [
        "To start we'll load our numpy module and convert our nested list into a numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXxtoz_7Gv-x"
      },
      "source": [
        "import numpy as np\n",
        "data_numpy = np.array(data_orig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iie9ElEwGv-0"
      },
      "source": [
        "data_numpy now holds all of the Titanic data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQG-_yXGGv-0",
        "scrolled": true
      },
      "source": [
        "# display numpy dataset\n",
        "print(data_numpy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU4cI5JsGv-4"
      },
      "source": [
        "Notice how numpy 2-dimensional data is printed across multiple rows rather than a continuous row as we've seen previously with nested lists.\n",
        "\n",
        "Since there are a large number of samples, we cannot display all of them at the same time. Instead we can verify the structure of the data by displaying some of the samples at a time. Before we can do that we first need to understand how the numpy comma slicing notation works."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CW6t5Iu5Gv-5"
      },
      "source": [
        "### Numpy Slicing\n",
        "\n",
        "Slicing in Numpy is done differently from what we've seen so far. To highlight the differences we will compare numpy indexing and slicing of 1-dimensional and 2-dimensional data and compare it to what we did for lists.\n",
        "\n",
        "#### 1-dimensional data: Indexing and Slicing\n",
        "\n",
        "To index a list we use square brackets [], and to slice a list we would use a colon operator:\n",
        "\n",
        "* list_variable[index]  \n",
        "* list_variable[start:end:step]\n",
        "\n",
        "The same can be done for numpy:\n",
        "\n",
        "* numpy_variable[index]  \n",
        "* numpy_variable[start:end:step]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szp8ahddGv-6",
        "scrolled": true
      },
      "source": [
        "list_variable = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
        "\n",
        "#list indexing\n",
        "print(list_variable[2])\n",
        "\n",
        "#list slicing\n",
        "print(list_variable[1:8:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEoXf26wGv-9",
        "scrolled": true
      },
      "source": [
        "numpy_variable = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
        "\n",
        "#numpy array indexing\n",
        "print(numpy_variable[2])\n",
        "#numpy array slicing\n",
        "print(numpy_variable[1:8:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OHTtCK2Gv_A"
      },
      "source": [
        "#### 2-dimensional data: Indexing and Slicing\n",
        "\n",
        "To index a 2-dimensional list (nested list) we attach a second set of square brackets []\\[\\], however we are not able to slice a nested list by row and column simultaneously. \n",
        "\n",
        "* list_variable\\[index1\\]\\[index2\\]  \n",
        "* list_variable\\[start:end:step\\]\\[start:end:step\\] -> does something completely different  \n",
        "\n",
        "To index a 2-dimensional numpy array we use the comma notation, which unlike with nested lists, allows us slice a numpy array simultaneously by column and row.\n",
        "\n",
        "* numpy_variable[index1,index2]  \n",
        "* numpy_variable[start:end:step, start:end:step]  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WW-ZlfOGv_B"
      },
      "source": [
        "list_variable = [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]\n",
        "\n",
        "# nested list indexing\n",
        "print(list_variable[2][0])\n",
        "\n",
        "# nested list slicing\n",
        "print(list_variable[0:2][0]) # creates a list of the first two rows, then gets the first element"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GDPOo50Gv_D"
      },
      "source": [
        "numpy_variable = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "\n",
        "# 2-d numpy array indexing\n",
        "print(numpy_variable[2, 0])\n",
        "\n",
        "# 2-d numpy array slicing\n",
        "# get the first two entries in the first column\n",
        "print(numpy_variable[0:2, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EYvS-x3Gv_G"
      },
      "source": [
        "Now we can go about verifying the format of the data by displaying some of the samples at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqz1vo20Gv_G",
        "scrolled": false
      },
      "source": [
        "# select first row\n",
        "print(data_numpy[0,:])\n",
        "print(data_numpy[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F80mWkFGv_J"
      },
      "source": [
        "# select first column\n",
        "print(data_numpy[:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipGqD1otGv_L",
        "scrolled": false
      },
      "source": [
        "# select first five columns and rows\n",
        "print(data_numpy[:5,:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvuauTwdGv_O"
      },
      "source": [
        "For our purposes it is not necessary to transpose the matrix as numpy allows for slicing columns and rows simultaneously.  \n",
        "\n",
        "If we did need to apply a transform, it can be done relatively easily using the numpy transpose methods as shown:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp-8Rlu2Gv_P",
        "scrolled": true
      },
      "source": [
        "print(data_numpy.transpose())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-QPtQSVGv_S"
      },
      "source": [
        "## Back to Predicting Passenger Survival\n",
        "\n",
        "Let's get back to our original goal which is to predict whether Rose and Jack survive the Titanic disaster.\n",
        "\n",
        "In order to do that we will need to examine the dataset in more detail. For example, perhaps there is a correlation between survival likelihood and particular passenger information, such as gender, class, age, etc. \n",
        "\n",
        "As a first step, we can try to determine how many males and females survived and how many did not. How can we do that?\n",
        "\n",
        "* one approach is to iterate through the passengers and create 4 accumulator variables to keep the counts:\n",
        "  1.   males_survived\n",
        "  2.   males_not_survived\n",
        "  3.   females_survived\n",
        "  4.   females_not_survived\n",
        "\n",
        "Hmmm... What if we wanted to compare the survival across classes. There are three classes and two states of survival, hence we would need 6 accumulator variables to capture all the combinations. Certainly there has to be a better way to do this than writing code for each situation.\n",
        "\n",
        "* Another option might be to keep track of indices of a particular feature, along with the indices of survival states. Once we have the indicies, we can find the indicies common to both lists and get our counts that way.\n",
        "\n",
        "Turns out this can be done relatively easily with numpy if we know which method to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryoWMbHUGv_T"
      },
      "source": [
        "### Obtaining Indices using Numpy\n",
        "\n",
        "Finding indices of specific values or range of values can be done using the np.where() method. \n",
        "\n",
        "numpy.where(condition[, x, y])  \n",
        "* Return elements, either from x or y, depending on condition.\n",
        "* If only condition is given, return indices where condition is True.\n",
        "\n",
        "Since we're only interested in obtaining indices, we'll only provide a one argument to the method which will return two arrays (of the same size) corresponding to the row and column indices where the condition is true. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sREyL06xGv_U",
        "scrolled": true
      },
      "source": [
        "numpy_data = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
        "print('numpy_data:\\n', numpy_data, '\\n')\n",
        "\n",
        "# obtain indicies with values > 7\n",
        "indices = np.where(numpy_data > 7)\n",
        "\n",
        "# display row and column indices\n",
        "print('all indices:', indices, '\\n')\n",
        "\n",
        "# display row indices\n",
        "print('row indices:', indices[0], '\\n')\n",
        "\n",
        "# display column indices\n",
        "print('col indices:', indices[1], '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSYNEjzLGv_Z"
      },
      "source": [
        "Note that the entries that are greater than 7 are: (1,3), (2,0), (2,1), (2,2), (2,2), and (2,3).\n",
        "\n",
        "Let's apply this now to find indices in our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eeM0DwHGv_b",
        "scrolled": true
      },
      "source": [
        "# obtain index of column with title 'Sex'\n",
        "sex_index = np.where(data_numpy[0,:] == 'Sex')\n",
        "\n",
        "# print indices\n",
        "print(sex_index)\n",
        "print(sex_index[0])\n",
        "\n",
        "# print value at index found\n",
        "print(data_numpy[0,sex_index[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGV0DPYXGv_h"
      },
      "source": [
        "# get indices of all male passengers\n",
        "indices_male = np.where(data_numpy[1:,sex_index[0][0]] == 'male')\n",
        "print(indices_male[0])\n",
        "\n",
        "# display the number of male passengers\n",
        "print(len(indices_male[0]))\n",
        "\n",
        "# compute percentage of male passengers\n",
        "percent = 100*len(indices_male[0])/len(data_numpy[:,sex_index])\n",
        "print(round(percent,2), '% male passengers')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJW3ycaM5qVw"
      },
      "source": [
        "# what is the percentage of female passengers?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny_t-_tAGv_j"
      },
      "source": [
        "Let us now use the numpy module to calculate the percentage of males and females that survived. To start we need to find the indices of the survivors, then we can move on to find the indices of the male and female passengers. \n",
        "\n",
        "Hmmm, which column was \"Survived\" again?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbuL_xlnGv_k"
      },
      "source": [
        "# obtain index of column with title 'Survived'\n",
        "survived_index = np.where(data_numpy[0,:] == 'Survived')\n",
        "print(survived_index[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYJe7nvcGv_m"
      },
      "source": [
        "To make it easier to search by field name, we can create a dictionary for easy indexing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgrgM_fpGv_n",
        "scrolled": false,
        "outputId": "99df4931-51bb-43b0-e66c-81368ccb27cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# loop through field names and populate a dictionary with indices\n",
        "fields = {}\n",
        "\n",
        "# cycle through the first row (i.e. fields) \n",
        "for i in range(len(data_numpy[0,:])):\n",
        "    fields[data_numpy[0, i]] = i\n",
        "\n",
        "print(fields)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'PassengerId': 0, 'Survived': 1, 'Pclass': 2, 'Name': 3, 'Sex': 4, 'Age': 5, 'SibSp': 6, 'Parch': 7, 'Ticket': 8, 'Fare': 9, 'Cabin': 10, 'Embarked': 11}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRkJV_2mGv_r"
      },
      "source": [
        "Now we can use the dictionary to quickly obtain the index of the filed we are intersted in searching.\n",
        "\n",
        "Let's find the percentage of male passengers that survived"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP7JIT3xGv_s",
        "scrolled": true
      },
      "source": [
        "# get indices for male passengers\n",
        "field1 = 'Sex'\n",
        "field1_val = 'male'\n",
        "male_indices = np.where(data_numpy[0:,fields[field1]] == field1_val)\n",
        "male_indices = list(male_indices[0])\n",
        "\n",
        "# get indices for surviving passengers\n",
        "field2 = 'Survived'\n",
        "survived_indices = np.where(data_numpy[0:,fields[field2]] == '1')\n",
        "survived_indices = list(survived_indices[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndd2XElxGv_x"
      },
      "source": [
        "Now that we have a list of indices of passengers that survived, and a separate list of indices for the ones that are males, how can we use that information to find the number of male survivors?\n",
        "\n",
        "There are a couple ways we could do this. One option is to convert our lists of indices into sets and take advantage of the set intersection method/operator (i.e. &)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y2fZfDIGv_x"
      },
      "source": [
        "# compute percentage that survived\n",
        "percent = 100*len(set(male_indices) & set(survived_indices))/len(male_indices)\n",
        "print(round(percent,2), '% of', field1_val, 'passengers survived')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcI4SfkzGv_z"
      },
      "source": [
        "We could do the same thing to find the percentage of female passengers that survived or even to find the percentage of first class, female passengeres who survived. But doing this would seem like a lot of code for each combination of characteristics. Why not write a function that generalizes?\n",
        "\n",
        "We are given some number characteristics (A, B, C) (e.g., A could be male, B could be first class, etc) and we want to find out the percentage of passengers with all of those characteristics that survived. The little algorithm we could write is:\n",
        "\n",
        "- find ind_A (the indices with characteristic A), ind_B, and ind_C and intersect them to form ind_characteristics\n",
        "- find ind_survived (the indices of all passengers who survived)\n",
        "- the length of ind_survived intersected with ind_characteristics divided by the length of ind_survived gives the proportion of surivors\n",
        "\n",
        "Since we want to be able to do this with any number of characteristics, lets put them in a list.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ggz5RhWLGv_0"
      },
      "source": [
        "def get_survival(characteristics):\n",
        "    \"\"\"Return the percentage of passengers with the (field, value) entries in \n",
        "       characteristics that survived.\n",
        "       characteristics is a list of the form [(field, value), (field, value), ...]\n",
        "    \"\"\"\n",
        "    indices = set()\n",
        "    for i in range(len(characteristics)):\n",
        "        # get search category\n",
        "        field = characteristics[i][0]\n",
        "        \n",
        "        # get value to search for\n",
        "        val = characteristics[i][1]\n",
        "        \n",
        "        # find the matching indices\n",
        "        new_indices = set(list(np.where(data_numpy[0:,fields[field]] == val)[0]))\n",
        "        \n",
        "        # intersect\n",
        "        if len(indices) == 0:\n",
        "            indices = new_indices\n",
        "        else:\n",
        "            indices &= new_indices\n",
        "            \n",
        "    # find the indices of the survivors    \n",
        "    indices_survived = set(list(np.where(data_numpy[0:,fields[\"Survived\"]] == \"1\")[0]))\n",
        "        \n",
        "    return 100*len(indices_survived & indices)/len(indices)\n",
        "\n",
        "percent = get_survival([(\"Sex\", \"male\")])\n",
        "print(round(percent,2), '% of male passengers survived')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOsqLSQDGv_2"
      },
      "source": [
        "Now we can easily do the same thing for other combinations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7lEfIAUGv_3"
      },
      "source": [
        "# find the percentage of female passengers that survived\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx9YSSyeGv_6"
      },
      "source": [
        "How about we combine gender and class to see how many first class males survived compared to other classes. How could we do that?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVA-XNv-Gv_7"
      },
      "source": [
        "# find the percentage of  male class 1 passengers that survived\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrVmuBRP6aMP"
      },
      "source": [
        "# find the percentage of  female class 1 passengers that survived\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6x-l_e8KGwAC"
      },
      "source": [
        "Let's now use the passenger gender and class to improve our prediction.\n",
        "\n",
        "#### Test Case 1:  Sample Male and Female Survivor\n",
        "  \n",
        "|Passenger|PassengerID|Pclass|Sex|Age|SibSp|Parch|Fare|Embarked_Val|\n",
        "|:--------|:----------|:-----|:--|:--|:----|:----|:---|:-----------|\n",
        "|Mrs. Laina Heikkinen|3|3|1|26|0|0|7.925|2|\n",
        "|Master. Michel Navratil|194|2|0|3|1|1|26|2|\n",
        "\n",
        "\n",
        "#### Test Case 2:  Sample Male and Female Non-Survivor\n",
        "\n",
        "|Passenger|PassengerID|Pclass|Sex|Age|SibSp|Parch|Fare|Embarked_Val|\n",
        "|:--------|:----------|:-----|:--|:--|:----|:----|:---|:-----------|\n",
        "|Miss. Augusta Planke|39|3|1|18|2|0|18|2|\n",
        "|Mr. Owen Harris Braund|1|3|0|22|1|0|7.25|2|"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KRxL64FGwAD",
        "scrolled": true
      },
      "source": [
        "# Estimate survival likelihood of the test case passengers and comment on the accuracy of the findings\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxR-Kf6DICa2"
      },
      "source": [
        "# Part 2\n",
        "\n",
        "# Problem: Visualizing Titanic Dataset\n",
        "\n",
        "This part will focus on visualizing the data to find patterns that may allow us to make a prediction on who would survive the Titanic tragedy.\n",
        "\n",
        "Python has many modules available dealing with visualization. One of the most popular to use is the **matplotlib module** which replicates the plotting capability of MATLAB (matplotlib is short for \"MATLAB plotting library). In what is to follow, we will discuss how to import and use this module.\n",
        "\n",
        "To start we can use the plot() method, which takes an optional format string argument that specifies the color and style of the plotted line. For example, plot(x_values, y_values, 'r--') uses 'r' to specify a red color, and '--' to specify a dashed line. You can find more information on formatting options at the following [link](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy8ezCAlICa2"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40RNIZYAICa5"
      },
      "source": [
        "The program imports the pyplot module from the matplotlib package, renaming matplotlib.pyplot to plt using the **as** keyword. \n",
        "\n",
        "The plt.plot() function plots data onto the graph. plot() accepts various arguments. If provided just one list, as in plt.plot(val), plot() uses 0, 1, ... for x values, as in (0, val[0]), (1, val[1]), etc. \n",
        "\n",
        "plt.plot() on its own will not display anyting. One needs to call the plt.show() function to displays the graph.\n",
        "\n",
        "To start let's plot the survival percentages based on gender:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YH4XytTICa6"
      },
      "source": [
        "# plot survival by gender\n",
        "male_survived = 18.9\n",
        "female_survived = 74.2\n",
        "survived_percent = [male_survived, female_survived]\n",
        "\n",
        "# plot survival percentages\n",
        "plt.plot(survived_percent)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5qKZDKgICa8"
      },
      "source": [
        "# plot survival with dotted connecting lines\n",
        "plt.plot(survived_percent, 'm--o')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGRaAb42ICa_"
      },
      "source": [
        "# plot survival without connecting lines\n",
        "plt.plot(survived_percent, 'mo', markerfacecolor = 'None')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ni03fpXRICbC"
      },
      "source": [
        "Calling plot multiple times draws multiple lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ_LRRmoICbD"
      },
      "source": [
        "# we can plot percentages of those that survived with overlapping percentages \n",
        "# of those that did not survive\n",
        "survived_percent = [male_survived, female_survived]\n",
        "n_survived_percent = [100 - male_survived, 100 - female_survived]\n",
        "\n",
        "plt.plot(survived_percent, 'm--o')\n",
        "plt.plot(n_survived_percent, 'r-.D')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WKP8oSSICbF"
      },
      "source": [
        "#### Text and Annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IAE_a1sICbG"
      },
      "source": [
        "# add title and axis labels\n",
        "plt.plot(survived_percent, 'm--o')\n",
        "plt.title('Survival Percentage Based on Gender')\n",
        "plt.ylabel('Percentage')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIEXlHj7ICbJ"
      },
      "source": [
        "# add tick labels\n",
        "plt.plot(survived_percent, 'm--o')\n",
        "plt.xticks([0, 1],['males', 'females'])\n",
        "plt.title('Survival Percentage Based on Gender')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Percentage')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db7OWO4QICbM"
      },
      "source": [
        "Hmmmm, this information would be best represented as a bar graph. Turns out we can do that as well using matlibplot.\n",
        "\n",
        "#### Bar Graphs - Averaged Data\n",
        "We can visualize the survival rates using bar graphs as shown:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVb5LeZ4ICbN"
      },
      "source": [
        "# plot bar graph of survival by gender\n",
        "pos = [0, 1]\n",
        "plt.bar(pos, survived_percent, align = 'center')\n",
        "plt.xticks(pos,['males survived', 'females survived'])\n",
        "plt.title('Survival Percentage Based on Gender')\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Percentage')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNd5Tbe6ICbQ"
      },
      "source": [
        "# plot bar graph of survival by class\n",
        "male_class_survived = [36.88, 15.74, 13.54]\n",
        "\n",
        "\n",
        "# x axis position of bars graph\n",
        "pos = range(len(male_class_survived))\n",
        "# generate bar graph\n",
        "plt.bar(pos, male_class_survived, align = 'center')\n",
        "# provide labels for each bar based on provided positions\n",
        "plt.xticks(pos,['1st', '2nd', '3rd'])\n",
        "plt.title('Survival Percentage of Males Based on Class')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Percentage')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkLuyfMmICbT"
      },
      "source": [
        "**(optional) We can also use subplots to plot everything together. In your spare time see if you can plot the percentage of male and female survivors using subplots.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Md2BUXqICbU"
      },
      "source": [
        "# (optional) use subplots to show male and female survivors by class\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCvP1KOHICbW"
      },
      "source": [
        "What if we wanted to plot an entire column? For example, we could print the ages of all the passengers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA03UisEICbY"
      },
      "source": [
        "#### Numpy: Converting Column of str to int\n",
        "When we loaded our data all the values were converted into strings because unlike lists numpy arrays can be of only one type (i.e. string or float, not both). This is somewhat problematic as we cannot plot strings, we need numerical values. We need to fix our dataset before we can plot it. How might we do that?\n",
        "\n",
        "If we want to plot the age of passengers we need to apply the following steps:\n",
        "\n",
        "1. Select the age column\n",
        "2. find all the missing ages and replace them with a numerical value (i.e. np.nan)\n",
        "3. convert the numpy array into a float\n",
        "\n",
        "Selecting the age column is something we've done, but what about finding and overwriting data? One option could be to find the indicies that are blank and overwrite them. There is an easier way to do this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAiGLmgKICbZ"
      },
      "source": [
        "Turns out we can also select numpy data by value using conditionals. For examples:\n",
        "    \n",
        "    x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "\n",
        "    x[x >= 5]\n",
        "    \n",
        "Will select only the data that is greater than or equal to 5 in a numpy array x.\n",
        "\n",
        "We can take this further by assigning that data a particular value.\n",
        "\n",
        "    x[x >= 5] = 100\n",
        "\n",
        "Will select only the data greater than or equal to 5 and change the value to 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4htYcx6KICbe"
      },
      "source": [
        "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "print(x[x >= 5])\n",
        "x[x >= 5] = 100\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gffNtq2HICbg"
      },
      "source": [
        "Now we can use the same technique to update our age data to numerical values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBLhsTkAICbh",
        "scrolled": true
      },
      "source": [
        "# select the age of passengers\n",
        "index = fields['Age']\n",
        "age = data_numpy[1:, index]\n",
        "\n",
        "# find the ones that are empty and make them nan\n",
        "age[age == ''] = np.nan\n",
        "\n",
        "# convert all the strings into floats\n",
        "age = age.astype(float)\n",
        "\n",
        "# verify conversion to float\n",
        "print(age)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEYXB7RAICbj"
      },
      "source": [
        "By making the missing data of type nan (not a number), plot will ignore those values when plotting age values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Odp_51ICbk"
      },
      "source": [
        "# plot age\n",
        "plt.plot(age)\n",
        "plt.title('Passenger Age')\n",
        "plt.xlabel('Passenger #')\n",
        "plt.ylabel('Age (years)')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqgU-KfyICbm"
      },
      "source": [
        "Since we don't care about the sequence of the age of passengers, it may be more informative to see how many passengers we have within each age group, i.e. plot a histogram of our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtbXEFPLICbn",
        "scrolled": true
      },
      "source": [
        "plt.hist(age, bins=30)\n",
        "plt.title('Passenger Age Histogram')\n",
        "plt.xlabel('Age (years)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAz5VuqbICbp"
      },
      "source": [
        "Hmmmm, seems like we obtain a histogram for nan values. How can we fix this? Let's search on Google to see if anyone else has had this problem. A quick search reveals the following stackoverflow discussion [(link)](http://stackoverflow.com/questions/11620914/removing-nan-values-from-an-array).\n",
        "\n",
        "    x = x[numpy.logical_not(numpy.isnan(x))] \n",
        "\n",
        "or   \n",
        "\n",
        "    x = x[~numpy.isnan(x)]\n",
        "\n",
        "This is actually the same as: \n",
        "\n",
        "    x = x[numpy.isnan(x) == 0]\n",
        "\n",
        "Let's use this to select all age values excluding the nan type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY6rn43FICbq"
      },
      "source": [
        "# plot a histogram of passenger ages excluding nan values\n",
        "# to plot the histogram we need to exclude the missing ages, i.e. nan values\n",
        "# the np.isnan() method returns True for values that are of type nan\n",
        "plt.hist(age[np.isnan(age) == 0], bins=30)\n",
        "plt.title('Passenger Age Histogram')\n",
        "plt.xlabel('Age (years)')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOaQ4wN8ICby"
      },
      "source": [
        "**(Optional) As another exploration activity, it might be useful to see how survival changes with age. To do that it might be helpful to plot the survivor and non-survivor age histograms overtop of each other. Hmmm, how might we do that?** [(Hint)](http://stackoverflow.com/questions/6871201/plot-two-histograms-at-the-same-time-with-matplotlib)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uybQTudDICbz"
      },
      "source": [
        "# (Optional) plot a histogram of passenger ages excluding nan values and overlap survivors and non-survivors. Does this provide any insight into the data?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLjhsu20ICb3"
      },
      "source": [
        "Including age with the class and gender may benefit our predictions on the test cases. It would take some work to implement this change. It may be a good idea to pause and reconsider our approach continuing any further.\n",
        "\n",
        "In the next part we will discuss how to take the information we have gained about our dataset to apply commonly used machine learning algorithms to predict passenger survival outcome."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdF9MqWLIhb8"
      },
      "source": [
        "# Part 3\n",
        "\n",
        "# Problem: Predicting Titanic Survivors\n",
        "\n",
        "After visualizing the data in the previous part, we can see that the odds of surviving vary depending on passenger information such as: age, sex, class. Is there some way we can use all our passenger information to predict survival?\n",
        "\n",
        "In this part we will take a look at how to use the readily available machine learning algorithms to make predictions on survival.\n",
        "\n",
        "The machine learning community has grown substantially over the years and there are many modules available to implement the different algorithms. To implement the algorithms, all we need to do is obtain a dataset and arrange it to follow the machine learning conventions which can be described by the following algorithm plan:\n",
        "\n",
        "### End-to-End Machine Learning Project:\n",
        "\n",
        "* Look at the big picture\n",
        "+ Get the data\n",
        "+ Visualize the data to gain insights\n",
        "+ Preprocess (clean) data to ensure all values are numerical\n",
        "+ Divide dataset into a training and testing set\n",
        "+ Select machine learning model and train it\n",
        "+ Perform prediction on the testing data\n",
        "+ Evaluate prediction performance of machine learning algorithm (use new data or holdout set to be sure of performance)\n",
        "\n",
        "Note that we've already completed steps 1 - 3 and we've already done a bit of work on step 4 when we ploted age of passengers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCN-VX6BE3yD"
      },
      "source": [
        "#### Replace strings and missing values with numbers\n",
        "\n",
        "As part of the data structure we require that all the samples are numerical. We need to prepare data by removing strings and filling in missing values.\n",
        "\n",
        "As we saw previously, we can select numpy data by value using conditionals. For examples:\n",
        "\n",
        "    x[numpy.isnan(x) == 0]\n",
        "\n",
        "Will select only the data that is not of type nan. Similarly,\n",
        "\n",
        "    x[x >= 5]\n",
        "    \n",
        "Will select only the data that is greater than or equal to 5 in a numpy array x.\n",
        "\n",
        "We can take this further by assigning that data a particular value. For example:\n",
        "\n",
        "    x[x >= 5] = 100\n",
        "\n",
        "Will select only the data greater than or equal to 5 and change the value to 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7ivBqhOIhcE",
        "scrolled": true
      },
      "source": [
        "# any value >= 5 will be replaced with 100\n",
        "x = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
        "x[x >= 5] = 100\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5lzY8hOIhcI"
      },
      "source": [
        "Now let's use that to fix our data to only hold numerical values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STrkVhxlIhcR"
      },
      "source": [
        "Let's put everything together into a class data structre and test. **Make sure that the trian.csv file is loaded.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAAB_wwiIhcS",
        "scrolled": true
      },
      "source": [
        "# Helper Titanic_Data Class\n",
        "\n",
        "# Correct values in Survival, Gender, Embarked, and Age columns\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "class Titanic_Data:\n",
        "    \"\"\"Titanic data set\"\"\"\n",
        "    \n",
        "    def __init__(self, Filename):\n",
        "        \"\"\"load Titanic data set\"\"\"\n",
        "        with open(Filename,'r') as csvfile:\n",
        "            data_reader = csv.reader(csvfile)\n",
        "            data_orig = []\n",
        "            for row in data_reader:\n",
        "                data_orig.append(row)\n",
        "        \n",
        "        # loop through field names and populate a dictionary with indices\n",
        "        fields = {}\n",
        "        for i in range(len(data_orig[0])):\n",
        "            fields[data_orig[0][i]] = i\n",
        "        \n",
        "        # exclude the first row when preparing the numpy data structure\n",
        "        self.data = np.array(data_orig[1:])\n",
        "        self.fields = fields\n",
        "    \n",
        "    def get_survival(self, characteristics):\n",
        "        \"\"\"Return the percentage of passengers with the (field, value) entries in \n",
        "           characteristics that survived.\n",
        "           characteristics is a list of the form [(field, value), (field, value), ...]\n",
        "        \"\"\"\n",
        "        indices = set()\n",
        "        for i in range(len(characteristics)):\n",
        "            # obtain search category\n",
        "            field = characteristics[i][0]\n",
        "        \n",
        "            # obtain value to search for\n",
        "            val = characteristics[i][1]\n",
        "        \n",
        "            # find and intersect the matching indices\n",
        "            new_indices = set(list(np.where(self.data[0:,self.fields[field]] == val)[0]))\n",
        "        \n",
        "            # intersect\n",
        "            if len(indices) == 0:\n",
        "                indices = new_indices\n",
        "            else:\n",
        "                indices &= new_indices\n",
        "            \n",
        "        # find the indices of the survivors    \n",
        "        indices_survived = set(list(np.where(self.data[0:,self.fields[\"Survived\"]] == \"1\")[0]))\n",
        "        \n",
        "        return 100*len(indices_survived & indices)/len(indices)    \n",
        "   \n",
        "    def clean_data(self):\n",
        "        \"\"\"Converts all data into numerical values \n",
        "        (missing data is converted into nan)\"\"\"\n",
        "        self.clean('Sex', ['male', 'female'])\n",
        "        self.clean('Embarked', ['C', 'Q', 'S'])\n",
        "        self.clean('Age')\n",
        "        self.clean('Pclass')\n",
        "        self.clean('SibSp')\n",
        "        self.clean('Parch')\n",
        "        self.clean('Fare')\n",
        "   \n",
        "    def clean(self, col_header, values = []):\n",
        "        \"\"\"Converts column data into numerical values\n",
        "        (missing data is convereted into nan)\"\"\"\n",
        "        # select the column\n",
        "        column = self.data[:,self.fields[col_header]]\n",
        "        # find the ones that are empty and make them nan\n",
        "        column[column == ''] = np.nan\n",
        "        # encode the the strings as numbers\n",
        "        for i in range(len(values)):\n",
        "            column[column == values[i]] = i\n",
        "        # overwrite\n",
        "        self.data[:,self.fields[col_header]] = column\n",
        "   \n",
        "    def keep_columns(self, L):\n",
        "        \"\"\"Select Features \"\"\"           \n",
        "        feature_data = self.data[:,L]\n",
        "        feature_data = feature_data.astype(float)\n",
        "        return feature_data\n",
        "\n",
        "# call function to prepare data structure\n",
        "titanic = Titanic_Data('train.csv')\n",
        "print(titanic.data[0,:])\n",
        "\n",
        "# cleaned data\n",
        "titanic.clean_data()\n",
        "print(titanic.data[0,:])\n",
        "\n",
        "# remove unnecessary columns and convert array to float\n",
        "feature_data = titanic.keep_columns([1, 2, 4, 5, 6, 7, 9, 11])\n",
        "print(feature_data[0,:])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "il8Y4yURIhcV"
      },
      "source": [
        "#### Divide data into a training and testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J7GmA54IhcV"
      },
      "source": [
        "feature_data = titanic.keep_columns([1, 2, 4, 5, 6, 7, 9, 11])\n",
        "\n",
        "# replace all nan values with -1 to prevent an error\n",
        "feature_data[np.isnan(feature_data)==1] = -1\n",
        "\n",
        "# segment data into training and testing datasets (features)\n",
        "halfway = len(feature_data)//2\n",
        "training_data = feature_data[0:halfway,1:]\n",
        "testing_data = feature_data[halfway:,1:]\n",
        "\n",
        "# segment data into training and testing labels (targets)\n",
        "training_labels = feature_data[0:halfway,0]\n",
        "testing_labels = feature_data[halfway:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFY-O9uZIhcY"
      },
      "source": [
        "# verify the training data and labels are correct\n",
        "print(training_data)\n",
        "print(training_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPGDorMdIhcb"
      },
      "source": [
        "#### Import a Machine Learning Algorithm\n",
        "There are many machine learning algorithms developed for making predictions (classification) similar to the one we are trying to do in this design problem. To use these algorithms we first need to import them from the scikit-learn machine learning modules for Python. More information on the different algorithms can be found at the following [link](http://scikit-learn.org/stable/).\n",
        "\n",
        "There are many machine algorithms to choose from such as:\n",
        "\n",
        "1. Decision Trees\n",
        "2. Random Forests\n",
        "3. Support Vector Machines\n",
        "4. NaÃ¯ve Bayes\n",
        "\n",
        "For now let us focus on the decision trees classifier. We import the classifier and setup some default parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4DoG2TrIhcc"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(max_depth=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVayKTwiIhcf"
      },
      "source": [
        "#### Train machine learning algorithm\n",
        "Next we train our algorithm on the training set. This updates the model parameters to make predictions specific to our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R0A5IsGIhcg"
      },
      "source": [
        "model.fit(training_data, training_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkRki_HsIhci"
      },
      "source": [
        "#### Perform prediction on the test cases.\n",
        "Now that model is trained, we can use it to predict the outcome on our test cases:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8ab_Sl0Ihcj"
      },
      "source": [
        "#### Test Case 1:  Sample Male and Female Survivor\n",
        "  \n",
        "|Passenger|PassengerID|Pclass|Sex|Age|SibSp|Parch|Fare|Embarked_Val|\n",
        "|:--------|:----------|:-----|:--|:--|:----|:----|:---|:-----------|\n",
        "|Mrs. Laina Heikkinen|3|3|1|26|0|0|7.925|2|\n",
        "|Master. Michel Navratil|194|2|0|3|1|1|26|2|\n",
        "\n",
        "#### Test Case 2:  Sample Male and Female Non-Survivor\n",
        "\n",
        "|Passenger|PassengerID|Pclass|Sex|Age|SibSp|Parch|Fare|Embarked_Val|\n",
        "|:--------|:----------|:-----|:--|:--|:----|:----|:---|:-----------|\n",
        "|Miss. Augusta Planke|39|3|1|18|2|0|18|2|\n",
        "|Mr. Owen Harris Braund|1|3|0|22|1|0|7.25|2|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XmBTJZoIhck"
      },
      "source": [
        "We first need to select our testcase samples. We can do that by obtaining the samples from the original feature data by providing their order in the list (i.e. PassengerID)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK6GY878Ihcl",
        "scrolled": false
      },
      "source": [
        "# select test case 1 and 2 passengers\n",
        "passenger_ids = np.array([3, 194, 39, 1])\n",
        "print(passenger_ids-1)\n",
        "testcase_data = feature_data[passenger_ids-1, 1:]\n",
        "\n",
        "# display details on selected passengers\n",
        "print(testcase_data)\n",
        "\n",
        "# predict survival outcome\n",
        "testcase_predict = model.predict(testcase_data)\n",
        "print('Predicted Survival Outcome: ', testcase_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqGVEsRnIhcn"
      },
      "source": [
        "On the above sample we see that our algorithm was able to successfully predict the survival outcome of the passengers in the test cases.\n",
        "\n",
        "Wait a second... it seems like all our test case samples are also in the training data. The algorithm was trained on the same data, which means they're going to do better on this data than on completely new data (i.e. testing_data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3die4ahIhco"
      },
      "source": [
        "Let's compare the prediction on the training_data and testing_data to get a proper validation of prediction performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDDZHy5IIhcp",
        "scrolled": true
      },
      "source": [
        "# predict the first 10 training samples and compare to the actual survival outcomes\n",
        "print('Training Sample Labels:     ', training_labels[0:10])\n",
        "sample_predict = model.predict(training_data[0:10,:])\n",
        "print('Predicted Survival Outcome: ', sample_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IhI8XrqIhcr"
      },
      "source": [
        "Seems like the prediction worked well on the training samples. How about the testing samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bL1GOG-Ihcs",
        "scrolled": false
      },
      "source": [
        "# test on the first 10 testing samples and compare to the actual survival outcomes\n",
        "print('Testing Sample Labels:      ', testing_labels[0:10])\n",
        "sample_predict = model.predict(testing_data[0:10,:])\n",
        "print('Predicted Survival Outcome: ', sample_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiMLqlBeIhcu"
      },
      "source": [
        "Already we see that some of the predictions were not correct."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw2mTBphIhcv"
      },
      "source": [
        "#### Evaluate performance by computing the percentage of correctly predicted survival outcomes.\n",
        "To get a true evaluation of performance we need to test on a larger set of data. Let's predict the outcome on all of the testing data and compute a percentage of how many survival outcomes were correctly predicted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7MWiQgpIhcw",
        "scrolled": true
      },
      "source": [
        "# obtain survival predictions on all testing data\n",
        "testing_predicted = model.predict(testing_data)\n",
        "\n",
        "# obtain a percentage score of performance on all testing data\n",
        "score = 100*(1-sum(abs(testing_predicted-testing_labels))/len(testing_predicted))\n",
        "print('Testing data performance', score, '% correctly predicted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78GQQvf7Ihcz"
      },
      "source": [
        "How does that compare with the samples obtained from the training data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVci4fKtIhc1"
      },
      "source": [
        "# obtain survival predictions on all training data\n",
        "training_predicted = model.predict(training_data)\n",
        "\n",
        "# obtain a percentage score of performance on all training data\n",
        "score = 100*(1-sum(abs(training_predicted-training_labels))/len(training_predicted))\n",
        "print('Training data performance', score, '% correctly predicted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRkTP0i4Ihc6"
      },
      "source": [
        "The prediction achieved better performance, 85.4% on the training data than the testing data 77.6%. This makes sense because the machine learning algorithms are trying to model the training data not the testing data.  \n",
        "\n",
        "Let's see if we can get better performance by adjusting the training parameters (i.e. max_depth) and applying other machine learning algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWfdJO_uIhc7"
      },
      "source": [
        "### Compare Prediction Performance Across Machine Learning Algorithms \n",
        "\n",
        "As a final step we will adjust our training parameters and machine learning algorithms to see if we can do any better on the survival prediction performance.\n",
        "\n",
        "Test **Decision Tree** Learning Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giGTsozmIhc8"
      },
      "source": [
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(max_depth=15)\n",
        "\n",
        "# Fit the model to our training data\n",
        "model.fit(training_data, training_labels)\n",
        "\n",
        "# Make predictions\n",
        "testing_predicted = model.predict(testing_data)\n",
        "score = 100*(1-sum(abs(testing_predicted-testing_labels))/len(testing_predicted))\n",
        "print(\"DT Test:\", score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GyLcmOoIhdA"
      },
      "source": [
        "There you go, youâ€™ve just implemented a high level prediction in only a couple lines. Since each dataset is different, we may find that there are other algorithms that are better suited for this prediction. Letâ€™s examine some of the other popular machine learning algorithms.\n",
        "\n",
        "Test **Random Forest** Learning Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9nlnxGsIhdB"
      },
      "source": [
        "# Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier(n_estimators=250)\n",
        "\n",
        "# Fit the model to our training data\n",
        "model.fit(training_data, training_labels)\n",
        "\n",
        "# Make predictions\n",
        "testing_predicted = model.predict(testing_data)\n",
        "score = 100*(1-sum(abs(testing_predicted-testing_labels))/len(testing_predicted))\n",
        "print(\"RF Test:\", score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc0w9z5ZIhdD"
      },
      "source": [
        "Test **Support Vector Machine** Learning Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sck7X0q7IhdE"
      },
      "source": [
        "# Support Vector Machines\n",
        "from sklearn import svm\n",
        "model = svm.SVC(gamma=2, C=1)\n",
        "\n",
        "# Fit the model to our training data\n",
        "model.fit(training_data, training_labels)\n",
        "\n",
        "# Make predictions\n",
        "testing_predicted = model.predict(testing_data)\n",
        "score = 100*(1-sum(abs(testing_predicted-testing_labels))/len(testing_predicted))\n",
        "print(\"SVM Test:\", score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-IHgAHlIhdI"
      },
      "source": [
        "Test **NaÃ¯ve Bayes** Machine Learning Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AB2P3_mJIhdI",
        "scrolled": true
      },
      "source": [
        "# Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "model = GaussianNB()\n",
        "\n",
        "# Fit the model to our training data\n",
        "model.fit(training_data, training_labels)\n",
        "\n",
        "# Make predictions\n",
        "testing_predicted = model.predict(testing_data)\n",
        "score = 100*(1-sum(abs(testing_predicted-testing_labels))/len(testing_predicted))\n",
        "print(\"NB Test:\", score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCEI3EXaIhdK"
      },
      "source": [
        "These are just a few of the available machine learning algorithms at our disposal. Designing these algorithms would have taken hours of work, fortunately, the Python open source community is strong and many people out there are willing to contribute. Hence, all we have to do is change one or two lines in our code to evaluate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPmKK-WoIhdL"
      },
      "source": [
        "## Perform Final Testing\n",
        "\n",
        "From the above algorithms tested, it seems like the Naive Bayes performed the best.  \n",
        "\n",
        "Now that we have selected our machine learning model for predicting survival, we can finally answer the question of whether or not Jack and Rose would have survived (test case 3). To make this prediction we need to provide information on the passengers in the expected form:\n",
        "\n",
        "|Passenger|Pclass|Sex|Age|SibSp|Parch|Fare|Embarked|\n",
        "|:--------|:-----|:--|:--|:----|:----|:---|:-----------|\n",
        "|Jack|3|0|25|0|0|7|2|\n",
        "|Rose|1|1|22|1|0|50|2|\n",
        "\n",
        "Given the provided information about Jack and Rose, would they have survived the tragedy?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8Zf8QIJIhdM"
      },
      "source": [
        "# Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(max_depth=15)\n",
        "\n",
        "# Fit the model to our training data\n",
        "model.fit(training_data, training_labels)\n",
        "\n",
        "# Create test data (features of Jack and Rose)\n",
        "test_jack = np.array([3, 0, 25, 0, 0, 7, 2])\n",
        "test_rose = np.array([1, 1, 22, 1, 0, 50, 2])\n",
        "\n",
        "testing_predicted = model.predict(test_jack.reshape(1,-1))\n",
        "print(\"Jack Survival:\", testing_predicted)\n",
        "\n",
        "testing_predicted = model.predict(test_rose.reshape(1,-1))\n",
        "print(\"Rose Survival:\", testing_predicted)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R09EqHKrIhdO"
      },
      "source": [
        "Our model **prediction is that Rose would survive and Jack would not**. You should watch the movie to find out if the prediction is correct.\n",
        "\n",
        "### Discussion\n",
        "Given that the accuracy for all of our models is maxing out around 80%, it will be interesting to look at specific passengers for whom these prediction algorithms are incorrect. Provided is a list of some of the passengers that were incorrectly predicted: \n",
        "\n",
        "#### Allison family\n",
        "For instance, three incorrectly classified passengers are members of the Allison family, who perished even though the model predicted that they would survive. These first class passengers were very wealthy, as can be evidenced by their far-above-average ticket prices. For Betsy (25) and Loraine (2) in particular, not surviving is very surprising, considering that we found earlier that over 96% of first class women lived through the disaster.  \n",
        "\n",
        "So what happened? A surprising amount of information on each Titanic passenger is available online; it turns out that the Allison family was unable to find their youngest son Trevor and was unwilling to evacuate the ship without him. Tragically, Trevor was already safe in a lifeboat with his nurse and was the only member of the Allison family to survive the sinking.\n",
        "\n",
        "#### John Jacob Astor\n",
        "Another interesting example is John Jacob Astor, who perished in the disaster even though the model predicted he would survive. Astor was the wealthiest person on the Titanic, an impressive feat on a ship full of multimillionaire industrialists, railroad tycoons, and aristocrats. Given his immense wealth and influence, which the model may have deduced from his ticket fare (valued at over \\$35,000 in 2016 dollars), it seems likely that he would have been among the 35 percent of men in first class to survive. However, this was not the case: although his pregnant wife survived, John Jacob Astorâ€™s body was recovered a week later, along with a gold watch, a diamond ring with three stones, and no less than \\$92,481 (2016 value) in cash.\n",
        "\n",
        "On the other end of the spectrum is Olaus Jorgensen Abelseth, a 25-year-old Norwegian sailor. Abelseth, as a man in 3rd class, was not expected to survive by our classifier. Once the ship sank, however, he was able to stay alive by swimming for 20 minutes in the frigid North Atlantic water before joining other survivors on a waterlogged collapsible boat and rowing through the night. Abelseth got married three years later, settled down as a farmer in North Dakota, had 4 kids, and died in 1980 at the age of 94.\n",
        "\n",
        "\n",
        "### Conclusions\n",
        "Initially I was disappointed by the accuracy of our machine learning models maxing out at about 80% for this data set. Itâ€™s easy to forget that these data points each represent real people, each of whom found themselves stuck on a sinking ship without enough lifeboats. When we looked into data points for which our model was wrong, we can uncover incredible stories of human nature driving people to defy their logical fate. It is important to never lose sight of the human element when analyzing this type of data set. This principle will be especially important going forward, as machine learning is increasingly applied to human data sets by organizations such as insurance companies, big banks, and law enforcement agencies.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4Vceh0OwtJX"
      },
      "source": [
        "## Take home questions\n",
        "\n",
        "(1) In performing our testing we have made some fundamental mistakes that results in overfitting to our 4 test cases. Spend some time looking through how we setup our training and testing data, in particular take a look at the test cases. Indicate what the problem is and suggest some ways to correct it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TfXAbGawsHO"
      },
      "source": [
        "# correct the above test process and evaluate the performance of the algorithms\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVBrnTnexzJM"
      },
      "source": [
        "(2) Exploration! Compare different machine learning algorithms and data preprocessing to see if you can achieve a better prediction accuracy. How can you be sure that you are not overfitting to the data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SEc_xNwyITV"
      },
      "source": [
        "# write your code here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}