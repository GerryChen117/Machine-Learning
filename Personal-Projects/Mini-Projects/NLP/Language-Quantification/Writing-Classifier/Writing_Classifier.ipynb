{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mystery Friend Writing Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’ve received an anonymous postcard from a friend who you haven’t seen in years. Your friend did not leave a name, but the card is definitely addressed to you. So far, you’ve narrowed your search down to three friends, based on handwriting:\n",
    "\n",
    "Emma Goldman\n",
    "Matthew Henson\n",
    "TingFang Wu\n",
    "\n",
    "But which one sent you the card?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we'll be building a writing classifier to distinguish one friend's writing from anothers. We will be using scikit-learn's bag-of-words and a Naive Bayes Classifier to get the job done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Goldman:\n",
      " Nor will the stereotyped\n",
      "Philistine argument that the laxity of divorce laws and the growing\n",
      "looseness of woman account for the fact that: first, every twelfth\n",
      "marriage ends in divorce; second, that since 1870 divorces have\n",
      "increased from 28 to 73 for every hundred thousand population; third,\n",
      "that adultery, since 1867, as ground for divorce, has increased 270.8\n",
      "per cent.; fourth, that desertion increased 369.8 per cent.\n",
      "\n",
      "Added to these startling figures is a vast amount of material,\n",
      "dramatic and literary, further elucidating this subject\n",
      "\n",
      "\n",
      "This is Henson:\n",
      "M.\n",
      "\n",
      "I was ashore on Duck Island in 1891, on my first voyage north, and I\n",
      "remember distinctly the cairn the party built and the money they\n",
      "deposited in it\n",
      "\n",
      "\n",
      "This is Wu:\n",
      " America is known to have a large number of such men and\n",
      "women, men and women who devote their time and money to preaching peace\n",
      "among the nations\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from goldman_emma_raw import goldman_docs\n",
    "from henson_matthew_raw import henson_docs\n",
    "from wu_tingfang_raw import wu_docs\n",
    "\n",
    "# import sklearn modules:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Setting up the combined list of friends' writing samples\n",
    "friends_docs = goldman_docs + henson_docs + wu_docs\n",
    "# Setting up labels for the three friends\n",
    "friends_labels = [1] * 154 + [2] * 141 + [3] * 166\n",
    "\n",
    "# Print out a document from each friend for a check:\n",
    "print(\"This is Goldman:\")\n",
    "print(goldman_docs[120])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"This is Henson:\")\n",
    "print(henson_docs[120])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"This is Wu:\")\n",
    "print(wu_docs[120])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated probabilities are: [Goldman Hensen Wu]\n",
      "[[1.10199321e-02 9.88977727e-01 2.34054697e-06]]\n",
      "\n",
      "\n",
      "The postcard was from Henson!\n"
     ]
    }
   ],
   "source": [
    "# This will be the test text:\n",
    "mystery_postcard = \"\"\"\n",
    "My friend,\n",
    "From the 10th of July to the 13th, a fierce storm raged, clouds of\n",
    "freeing spray broke over the ship, incasing her in a coat of icy mail,\n",
    "and the tempest forced all of the ice out of the lower end of the\n",
    "channel and beyond as far as the eye could see, but the _Roosevelt_\n",
    "still remained surrounded by ice.\n",
    "Hope to see you soon.\n",
    "\"\"\"\n",
    "\n",
    "# Create bow_vectorizer, this will help us construct the bag-of-words (BoW) automatically:\n",
    "bow_vectorizer = CountVectorizer()\n",
    "\n",
    "# Define friends_vectors, fit a BoW dict on the training data and return the vectorized results of the sentences.\n",
    "# The language model will learn from the vectorized form, whose word indices are based on the BoWs dict\n",
    "# Note: A bag-of-words vector will be the same length as the features dictionary / BoW dict, which is a map of each unique word token in the training data to a vector index:\n",
    "friends_vectors = bow_vectorizer.fit_transform(friends_docs)\n",
    "\n",
    "# Define mystery_vector, vectorize the test text based on the word indices of the trained PoW dict: \n",
    "mystery_vector = bow_vectorizer.transform([mystery_postcard])\n",
    "\n",
    "# Define friends_classifier (Naive Bayes):\n",
    "friends_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier on the training data and labels:\n",
    "friends_classifier.fit(friends_vectors, friends_labels)\n",
    "\n",
    "# Make the prediction using the trained model on the test text:\n",
    "predictions = friends_classifier.predict(mystery_vector)\n",
    "\n",
    "# See how confident the model is in it's classification by printing the estimated probabilities:\n",
    "predictions_proba = friends_classifier.predict_proba(mystery_vector)\n",
    "print(\"The estimated probabilities are: [Goldman Hensen Wu]\")\n",
    "print(predictions_proba)\n",
    "print(\"\\n\")\n",
    "\n",
    "mystery_friend = predictions[0] if predictions[0] else \"someone else\"\n",
    "\n",
    "if mystery_friend == 1:\n",
    "    writer = \"Goldman\"\n",
    "elif mystery_friend == 2:\n",
    "    writer = \"Henson\"\n",
    "else:\n",
    "    writer = \"Wu\"\n",
    "\n",
    "# Reveal who the Mystery Writer was:\n",
    "print(\"The postcard was from {}!\".format(writer))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddee34380c017b9a4435766bf49bcbd068cf54965e227858e99aeddcf59dc6ac"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
